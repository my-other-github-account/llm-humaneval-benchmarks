{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d8974d-c534-4c07-b780-cda0d0a06d56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2155ec61-375b-47a4-9e36-4bdfb1d1551f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"<KEY>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b758f0-44aa-41ac-80f9-e271fdebedc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from evalplus.data import get_human_eval_plus, write_jsonl\n",
    "\n",
    "problems = get_human_eval_plus()\n",
    "\n",
    "num_samples_per_task = 1\n",
    "len(list(problems.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de9eabb-5a58-4202-8730-82c5325fda99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def run(prompt, seed, port = 5000):\n",
    "    while True:  # Keep trying until we break out\n",
    "        try:\n",
    "            result = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4\",\n",
    "                # model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant. Please complete the following code snippet.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ],\n",
    "                temperature=0.0,\n",
    "                max_tokens=500,\n",
    "                n=1\n",
    "            )\n",
    "\n",
    "            response = result['choices'][0][\"message\"][\"content\"]\n",
    "            return response\n",
    "        except Exception as e:  # If we hit the rate limit\n",
    "            print(e)\n",
    "            time.sleep(1)  # Wait for a second before retrying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b6101a-3aeb-4cdf-a95b-a08044f6c6e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_function_body(code):\n",
    "    lines = code.splitlines()\n",
    "    function_lines = []\n",
    "    found_def = False\n",
    "\n",
    "    for line in lines:\n",
    "        # If 'def ' is found in a line, mark that we've entered the function\n",
    "        if 'def ' in line:\n",
    "            found_def = True\n",
    "            function_lines.append(line)\n",
    "            continue\n",
    "\n",
    "        # If we've entered the function, stop including lines when we hit a line that contains text but does not start with a whitespace character\n",
    "        if found_def and line.strip() != '' and not line.startswith((' ', '\\t')):\n",
    "            break\n",
    "\n",
    "        # Always include the line in the function lines\n",
    "        function_lines.append(line)\n",
    "\n",
    "    return '\\n'.join(function_lines)\n",
    "\n",
    "def cut_off_prefix(s):\n",
    "    idx_from = s.find('from ')\n",
    "    idx_def = s.find('def ')\n",
    "    idx_import = s.find('import ')\n",
    "\n",
    "    # Check if none of the keywords were found\n",
    "    if idx_from == -1 and idx_def == -1 and idx_import == -1:\n",
    "        return s\n",
    "\n",
    "    # Prepare a list of found indices, excluding those where the keyword was not found\n",
    "    indices = [idx for idx in [idx_from, idx_def, idx_import] if idx != -1]\n",
    "\n",
    "    # Return the string starting from the earliest found keyword\n",
    "    return s[min(indices):]\n",
    "    \n",
    "def generate_one_completion(prompt_code, seed = -1, port = 5000, long_prompt = False, user_tag = \"HUMAN:\", assistant_tag = \"AI MODEL:\", system_prefix = \"\"):\n",
    "    print(seed)\n",
    "    # suffix = 'def'+prompt_code.split(\"def\")[1].split(\"(\")[0]+\"(\"\n",
    "    suffix = \"\"\n",
    "    if long_prompt:\n",
    "        prompt = \"\"\"%s\n",
    "%s\n",
    "Complete the following Python code: \n",
    "Notes: respond with the entire complete function definition\n",
    "do not add any comments, be as concise in your code as possible\n",
    "use only built-in libraries, assume no additional imports other than those provided (if any)\n",
    "\n",
    "code:\n",
    "%s\n",
    "\"\"\" % (system_prefix, user_tag, prompt_code)# , assistant_tag, suffix)\n",
    "    else:\n",
    "        prompt = \"\"\"```\n",
    "%s\n",
    "```\"\"\" % prompt_code\n",
    "    \n",
    "    code_result = run(prompt, seed = seed, port = port)\n",
    "    # result = \"\\n\".join(code_result.split(\"def\")[-1].split(\"\\n\")[1:]).split(\"```\")[0]\n",
    "    result = cut_off_prefix(code_result)\n",
    "    result = get_function_body(result)\n",
    "    print(\"####\", prompt, \"####\")\n",
    "    print(\"***\", result, \"***\")\n",
    "    return result\n",
    "\n",
    "import itertools\n",
    "\n",
    "def run_benchmark(filename, maxnum=-1, port=5000, long_prompt = False, user_tag = \"\", assistant_tag = \"\", system_prefix = \"\"):\n",
    "    iterc = itertools.count()\n",
    "    problem_keys = list(problems)[:maxnum]\n",
    "    all_samples = []\n",
    "\n",
    "    for idx, task_id in enumerate(problem_keys):\n",
    "        # Generate real completions\n",
    "        for _ in range(num_samples_per_task):\n",
    "            completion = generate_one_completion(problems[task_id][\"prompt\"], seed=next(iterc), port=port, long_prompt = long_prompt, user_tag = user_tag, assistant_tag = assistant_tag, system_prefix = system_prefix)\n",
    "            all_samples.append(dict(task_id=task_id, completion=completion))\n",
    "\n",
    "        # Create a temporary copy of all_samples, to which we will append 'pass' completions\n",
    "        temp_samples = all_samples.copy()\n",
    "        \n",
    "        # Append 'pass' completions for the rest of the tasks\n",
    "        for remaining_task_id in list(problems)[idx+1:maxnum] + list(problems)[maxnum:]:\n",
    "            for _ in range(num_samples_per_task):\n",
    "                temp_samples.append(dict(task_id=remaining_task_id, completion=\"    pass\"))\n",
    "        \n",
    "        # Write all samples to the file, overwriting it completely\n",
    "        write_jsonl(filename, temp_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2412b0-788f-4aba-9f73-cccc7a9db504",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_benchmark(\"gpt4_final_500c_long.jsonl\", maxnum=-1, port=5000, long_prompt = True, user_tag = \"\", assistant_tag = \"\", system_prefix = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c9606-0951-4eeb-8179-9abfebdfe771",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c487464-c6f4-43b7-98af-2ad4aa2ec24c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
